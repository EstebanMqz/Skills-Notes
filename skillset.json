

// grep -c '{' skillset.json | tr -d '[:space:]' : 37 skills tagged/reviewed. 

{
    "data_science": {
      "description": "Aptitude using a wide-range of interdisciplinary technologies, algorithms, frameworks & web services in order to implement complex mathematical & statistical models with structured/unstructured data to have it processed for businesses.",
      "tags": ["#Data", "Data-mining", "AI", "ML", "Statistical Models", "Business-Insights", "Predictive Analytics"]
    },
    
    "data_analysis": {
      "description": "Advocate of following structured methods to process data, allowing me to make data cleansing & transformations to understand it fully while being able to uncover hidden patterns.",
      "tags": ["#Data-analysis", "#Data-modeling", "#Decision-making", "Data-cleansing"]
    },

    "business analytics": {
      "description": "High level of comepetence using a wide range of data analysis tools & statistical models to identify, extract & construct relevant business insights and their relation with variables of interest to enable making business data-driven decisions.",
      "tags": ["#Business-insights", "#Data-processing", "#Statistical-methods", "#Data-driven decisions"]
    },

    "business_intelligence": {
      "description": "Skilled implementing, reviewing & correcting statiscal/quantitative models to ensure the usage libraries modules & software tools to confidently explain and provide the business insights using powerful Data Visualization interactive tools.",
      "tags": ["#Business intelligence", "#Analytics", "PowerBI", "Tableau", "Advanced Excel"]
    },

    "big_data": {
      "description": "Experience manipulating large datasets that contain millions of records to effectively automate CI/CD pipelines locally including feature engineering.",
      "tags": ["#Data-Engineering", "#Data-lake", "#Data-warehousing", "#SQL", "Data-Mining"]
    },

    "machine_learning": {
      "description": "Competence in major branch of AI for classification, clustering, optimization, forecasting processes using CI/CD pipelines.",
      "tags": ["#Deep-learning", "#Neural-networks", "#AI", "Statistical-learning", "#Time-series modelling", "Predictive-modelling"]
    },    

    "data_cleansing": {
      "description": "Handling datasets duplicate & missing values, standardizing data, handling outliers and processing dtypes (e.g text-processing NLP/NTLK) & white noise reduction for temporal data.",
      "tags": ["#Data-cleansing", "#Outliers", "#Standarization", "#DQR"]
    },

    "data_modeling": {
      "description": "Passionate about automating abstraction processes through code to efficiently/repetitively make conceptual representations from hidden structures & patterns to make relationships using a variety of programming languages/tools.",
      "tags": ["#Data-modeling", "#Abstraction", "#Programming-languages", "#Software"]
    },

    "optimization modeling": {
      "description": "Experienced Programming minimizing/maximizing objective functions with/without constraints in order for the algorithm to iterate to the best uni/multi-variate solutions.", 
      "tags": ["#Optimization-modeling", "#Nonlinear-Programming", "#Linear-Programming", "#StochasticOptimization", "#ConvexOptimization", "#Scikit-learn"]
    },

    "predictive_modeling": {
      "description": "Adept programming CI/CD pipelines with tools/frameworks & cloud/local hosting services to make uni/multivariate forecasts with continuously integrated prediction responses.",
      "tags": ["#Predictive-modeling", "#Data-mining", "#Machine-learning", "#Forecast"]
    },

    "timeseries modelling": {
      "description": "Skilled implementing white noise reduction techniques, modeling trends, seasonality, autocorrelation as well as the analysis of other temporal patterns on time-series for predictive purposes.",
      "tags": ["#Seasonality", "#Trend", "#Autocorrelation", "#White-noise", "#Temporal-data", "Forecasting", "Pandas", "Numpy"]
    },

    "statistical_analysis": {
      "description": "Inclination to use statistical methods & mathematical properties to further implement simulation techniques from distributions of data in order to make models consider probabilities through Stochastic/Quantitative methods in LateX.",
      "tags": ["#Stochastic-calculus", "#Quantitative-methods", "#Statistical-learning", "Probabilistic-approach"]
    },

    "artificial_intelligence": {
      "description": "Passionate implementing ingrained task-executions in embedded systems without explicitly being programmed to do so.",
      "tags": ["#Ntlk", "#Cloud-hosting", "#Datewarehousing", "#CI/CD", "#Embedded systems"]
    },

    "deep learning": {
      "description": "Competent in the theory and practice of deep learning, including neural network architectures such as CNNs, RNNs, GANs, and LSTM, as well as optimization algorithms and regularization techniques. Experience  using Deep Learning Frameworks such as TensorFlow, PyTorch & Neural Network/Deep Learning Toolbox.",
      "keywords": ["Deep_neural-networks", "CNN", "RNN", "LSTM", "GANs", "DBNs", "PyTorch", "Deep Neural Network Toolbox", "Neural Network Toolbox", "Natural_language-processing"]
    },

    "neural_networks": {
      "description": "Experienced programming NN, including mathematically proposing their Activation/Loss functions, Layers & Weigts, preventing under/overfitting while determining and interpreting effectively the model's metrics & tools such as Confussion Matrix, Accuracy, Precision, Recall, F1 scores, ROC & AUC, RMSE, MAE, MSE, MAPE, etc.",
      "tags": ["#Deep-Learning", "Layers/Neurons", "Weights", "#Evaluation-metrics", "#Activation/loss-functions", "#Overfitting", "#Confussion-matrix", "#Accuracy", "#Precision", "#Recall", "#F1 scores", "#ROC curves", "#AUC"]
    },
    
    "data_visualization": {
      "description": "Proficiency using the most updated Data Visualization Libraries & Dashboard-tools (Matplotlib, Seaborn, Plotly-Dash, ggplot, Streamlit, Advanced Excel, PowerBI, Tableau & others). Expertise most existing Plot-types for business-insights storytelling.", 
      "tags": ["ipywidgets", "Plotly-Dash", "#Interactivity", "#UX/UI-Design"]
    },

    "tableau": {
      "description": "Working on certifying as a Tableau Desktop Specialist be able to provide professionaly the powerful Data Visualization software / real-time collaborations through interactive dashboards including a wide-range of customizations.",
      "tags": ["#Dashboards", "#Data-visualization", "#Interactivity", "#Tableau Desktop Specialist", "Online-Server"]
    },

    "natural_language_processing": {
      "description": "Experienced implementing the subset of AI within ML that includes powerful algorithms to preprocess text/speech, sentiment's analysis and Supervised/Unsupervised learning algorithms.",
      "tags": ["#NTLK", "NLP", "Text-Processing", "Sentiment-Analysis", "Speech-Recognition"]
    },
    
    "supervised_learning": {
      "description": "Proficiency implementing a variety of classification algorithms on categorical data such as random forest, SVMs, linear/logistic regressions, decision trees, etc. GIS Professional experience remote sensing Natural Protected Areas of pressure with PCA/Image_Differences algorithms.",
      "tags": ["#Supervised classification", "#Machine-learning", "#Categorical-data", "Continuous-random-variables", "#GIS", "Satellite-imagery"]
    },
    
    "unsupervised_learning": {
      "description": "Experienced implementing a wide-rannge of Machine-Learning algorithms on non categorical data including training & testing models for anomaly detection, dimensionality reduction, clustering algorithms, etc..",   
      "tags": ["#Unsupervised-learning", "#Continous-random-variables", "Simulations", "#Training-testing", "#Patterns"]
    },

    "CI/CD": {
      "description": "Used to implement CI/CD processes with a variety of web hosting services to automate the process of building & testing features.",
      "tags": ["#Continuous-deployment", "#Continuous-Integration", "#Feature branching", "#Team-collaborations", "Continuous automation"]
    },

    "data_engineering": {
      "description": "Fixed using extraction/collection methods to use a wide-range of Data Science/Analytics/Machine Learning techniques implementing ETL effectively and data-management cloud hosting services to maintain CI/CD pipelines.",
      "tags": ["#Designing", "#Building", "#Data-Architecture", "Data-Warehousing"]
    },

    "data_migration": {
      "description": "Skilled using and enabling automated virtual working environment for teams to ensure collaboration and increase reliability including my own, being able to personally setup my working environments anywhere.",
      "tags": ["#Virtual-environments", "#Reliability", "#Consistecy", "#Collaboration", "Communication", "Readability", "Functionality", "Modularity"]
    },

    "web_scraping": {
        "description": "High-level of proficciency using cloud data extraction methods such as .git & .html to the extent of creating complex scripting programs with them & a variety of programming languages in compliance with applicable laws.", 
        "tags": ["#Web-scraping", "#Data-Extraction", "Data-Mining", "#Legal-compliance", "Disclaimer", "LICENSE", "Privacy-Rights"]
    },

    "devops/project_management": {
      "description": "Adept ensuring healthy devops & IT practices to guarantee CI/CD pipelines are maintained while also being used handling project's management to ensure collaborations.",
      "tags": ["#Devops", "#IT-operations", "#CI/CD", "#Project-Planning", "#Collaborations", "Team-management"]
    },
      
    "market_risk_management": {
      "description": "Experienced managing market risks for arbitrage / portfolio hedging / capital management purposes to help institutions/individuals achieve their financial goals or provide investment services effectively.",
      "tags": ["#Commodities, Forex, Interest rates, Bonds", "#Portfolio-hedging", "Optimizations", "#Sharpe-Sortino-Calmar-Burke-Kappa_Omega--Traynor-Jensen-Proposed-Ratios", "#Sigma_corr._cov._Î²", "Simulations", "Forecast"]
    },

    "credit_risk": {
      "description": "Strong background in Statistics & Mathematics that allow me to manage & understand interest rates to detail to effectively manage default's risk for financial institutions while also being able to predict eligibility of loans.",
      "tags": ["#Financial-risk", "#Loan-Approval", "#Credit-Scoring", "#Default-Predictions"]
    },

    "simulation modeling": {
      "description": "Used to develop mathematical process practically to elaborate simulation models by determining the distribution of data & model them to detail in order to analyze being able to predict data with limited entries with unreal precision.",
      "tags": ["#Probabilities", "Statistics", "#Stochastics", "#Quantitative-methods", "Data-Distributions", "Continuous-Random-Variables", "Discrete-Random-Variables", "#Statistical-programming", "Data-Modelling"]
    },

    "Linear programming": {
      "description": "High level of expertise modelling optimization algorithms to achieve the best solutions including a big number of variables processed.",
      "tags": ["#Linear programming", "#Mathematical-modelling", "#Capital-allocation", "#Portfolio-optimization", "Objective-Functions", "#Constraints"]
    },

    "Functional_programming": {
        "description": "Expert using the programming paradigm efficiently/effectively enabling code reusability, readability, consistency and modularity is enabled to make data accesible for myself as well as for my team/organization.",
        "tags": ["#Immutability", "#Lambda-Functions", "Global/local functions", "#Code-Reusability", "#Recursion", "Simplicity"]
    },

    "object_oriented_programming": {
      "description": "Experienced using the programming paradigm based on objects that may contain data as field, code or procedures.",
      "tags": ["#Object oriented programming", "#Objects", "#Data-inmutability", "Modular-programming", "#Readability", "#Reusability"]
    },

    "Git": {
      "description": "Git versioning control mastery and more than a half decade of CLI & shell scripting experience to have full control of systems resources & ensure team collaborations.",
      "tags": ["#Git", "#version control", "#scripting", "shell-linux", "#team-collaboration", "communication"]
    },

    "Github/Gitlab": {
      "description": "High-level of expertise configuring CI/CD pipelines using public/private cloud hosting services like Github, Gitlab, Azure, Bitbucket with git & knowledge of other team-collaboration such as Subversion.", 
      "tags": ["#version control", "web hosting", "collaborations", "github", "azure", "gitlab", "bitbucket", "gitkraken"]
    },

    "Azure-devops": {
      "description": "Advocate of cloud hosting services & existing world-wide third-party apps/services to config. public/private CI/CD pipelines using features branches with copyright disclaimers.",
      "tags": ["#machine learning", "#cloud computing", "#integration", "pipelines CI/CD", "#data warehousing"]
    },

    "Data_Privacy": {
      "description": "Competence researching and implementing legal measures & disclaimers for to use cloud hosting services securely in order to ensure personal data copyrights & valuable data extraction methods in accordance with applicable laws.",
      "tags": ["#data privacy", "#protection", "#personal information", "#unauthorized access"]
    },

    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
  



    
























    

